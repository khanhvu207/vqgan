dataset: 
  target: FFHQDataModule
autoencoder:
  double_z: False
  z_channels: 256
  resolution: 256
  in_channels: 3
  out_ch: 3
  ch: 128
  ch_mult: [1, 1, 2, 2, 4]
  num_res_blocks: 2
  attn_resolutions: [16]
  dropout: 0.0
vector_quantization:
  quantizer: STQuantize
  params:
    num_codes: 1024
    code_dim: 32
    commitment_cost: 0.25
transformer:
  model_type:
  n_layer: 12
  n_head: 12
  n_embd: 768
  vocab_size: 1025
  block_size: 257
  embd_pdrop: 0.0
  resid_pdrop: 0.0
  attn_pdrop: 0.0
train_1st_stage:
  loss_fn:
    target: VQLPIPSWithDiscriminator
    params:
      disc_start: 100000
      codebook_weight: 1.0
      pixelloss_weight: 1.0
      disc_num_layers: 3
      disc_in_channels: 3 
      disc_factor: 1.0
      disc_weight: 0.2
      perceptual_weight: 1.0
      use_actnorm: False
      disc_conditional: False
      disc_ndf: 64
      disc_loss: hinge
  img_res: 256
  batch_size: 32
  grad_accum: 1
  log_every: 500
  max_steps: 1000000
  lr: 4.5e-6
  min_lr: 0
  lr_warmup: 0.01
  weight_decay: 0.0
  num_workers: 4
  gpus: 
  - 0
  - 1
  - 2
  - 3
train_2nd_stage:
  batch_size: 16
  max_steps: 25000
  lr: 1e-4
  min_lr: 0
  lr_warmup: 0.0
  weight_decay: 0.1
  num_workers: 4
  gpus: 
  - 0
  - 1
  - 2
  - 3
