{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "run_id = os.environ.get(\"RUN_ID\")\n",
    "assert run_id != None, f\"Can't detect the run with {run_id}\"\n",
    "\n",
    "from vqvae import VQModel\n",
    "\n",
    "import umap\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from utils import inmap, outmap\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQModel.load_from_checkpoint(f\"../logs/{run_id}/{run_id}.ckpt\").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CIFAR10(\"../data\", train=False, transform=T.Compose([\n",
    "        T.PILToTensor(),\n",
    "    ])\n",
    ")\n",
    "num_img = 16\n",
    "x = [data[i][0].unsqueeze(0) for i in range(num_img)]\n",
    "x = torch.vstack(x)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    h = inmap(x).to(device)\n",
    "    h = model.encoder(h)\n",
    "    h = model.quant_conv(h)\n",
    "\n",
    "    quant, _, _ = model.quantize(h)\n",
    "    quant = model.post_quant_conv(quant)\n",
    "\n",
    "    dec = model.decoder(quant).cpu()\n",
    "    x_recon = outmap(dec)\n",
    "\n",
    "assert x_recon.shape == (num_img, 3, 32, 32), f\"z_hat is of shape {x_recon.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(x, x_recon):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(40, 20))\n",
    "    ax[0].imshow(np.transpose(x.numpy(), (1, 2, 0)), interpolation='nearest')\n",
    "    ax[1].imshow(np.transpose(x_recon.numpy(), (1, 2, 0)), interpolation='nearest')\n",
    "    for axis in fig.axes:\n",
    "        axis.get_xaxis().set_visible(False)\n",
    "        axis.get_yaxis().set_visible(False)\n",
    "    plt.savefig(f\"{run_id}-recon.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(x), make_grid(x_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = umap.UMAP(n_neighbors=3,\n",
    "                 min_dist=0.1,\n",
    "                 metric='cosine').fit_transform(model.quantize.embedding.weight.data.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(proj[:,0], proj[:,1], alpha=0.3)\n",
    "plt.savefig(f\"{run_id}-codebook_embedding.pdf\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
